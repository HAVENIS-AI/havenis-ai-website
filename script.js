const LANGUAGE_DATA = {
    de: {
        "skip_to_content": "Zum Inhalt springen", "nav_partners": "Design‑Partner", "nav_why": "Warum jetzt?", "nav_training": "KI-Training", "nav_team": "Team", "nav_pilot": "Pilot-Ergebnisse", "nav_inv": "Investoren", "nav_call": "Intro‑Call", "nav_faq": "FAQ", "nav_contact": "Kontakt",
        "hero_h1": "KI, die wahrnimmt – ohne zu berühren", "hero_p": "Kontaktlose Erkennung von Anwesenheit, Atmung und Bewegungsmustern – für Sicherheit, Pflege und Komfort.", "hero_access_btn": "🚀 Early Access", "hero_tech_btn": "📶 Technologie", "badge_privacy": "🔒 Privacy‑by‑Design", "badge_device": "🧠 On‑Device", "badge_wifi": "📡 Bestehendes Wi‑Fi",
        "why_now_h2": "Warum jetzt?", "why_now_subtitle": "Technische Reife + Privacy‑Shift + Kosten/Nutzen.", "why_now_c1_h": "Wi‑Fi 6/7 + CSI", "why_now_c1_p": "Stabilere Metriken, höhere Auflösung und Zuverlässigkeit.", "why_now_c2_h": "Privacy‑Shift", "why_now_c2_p": "Wachsende Ablehnung von Kameras in Privaträumen.", "why_now_c3_h": "Edge‑AI", "why_now_c3_p": "Leistungsstarke NPUs ermöglichen lokale Echtzeit-Analyse.", "why_now_c4_h": "Kosten", "why_now_c4_p": "Nutzt vorhandene APs – kein dedizierter Sensor-Kauf.",
        "tech_h2": "Wie Wi‑Fi‑Sensing funktioniert", "tech_subtitle": "Bewegung verändert die Reflexion von Funksignalen. Unsere KI-Modelle interpretieren diese winzigen Muster in Echtzeit.", "tech_c1_h": "1. Signal‑Erfassung", "tech_c1_p": "Wi-Fi Access Points senden und empfangen ständig Signale. Jede Bewegung – selbst die Atmung – verändert diese Signale auf charakteristische Weise (CSI-Daten).", "tech_c2_h": "2. KI‑Dekodierung", "tech_c2_p": "Ein lokales Deep-Learning-Modell analysiert die CSI-Datenströme und extrahiert daraus anonyme Bewegungsprofile, Atemraten und Körperhaltungen – ohne Cloud.", "tech_c3_h": "3. Nützliche Ereignisse", "tech_c3_p": "Die erkannten Muster werden in konkrete Events übersetzt: Sturz erkannt, Person anwesend, unruhiger Schlaf. Diese Events lösen dann Alarme oder Aktionen aus.",
        "howitworks_h2": "Vom Funksignal zur Körperhaltung", "howitworks_subtitle": "Unsere Technologie basiert auf dem Prinzip des \"Knowledge Distillation\", inspiriert durch Forschung der Carnegie Mellon University (\"DensePose from WiFi\").", "howitworks_train_h": "Wissenstransfer: Wie die KI lernt", "howitworks_train_p": "Im Labor bringen wir unserer KI bei, Wi-Fi-Muster mit Körperhaltungen zu verknüpfen. Eine Kamera-KI dient dabei als \"Lehrer\", der sein Wissen an die Wi-Fi-KI (\"Schüler\") weitergibt.", "howitworks_teacher": "👁️ Kamera (Lehrer-KI)", "howitworks_arrow": "→", "howitworks_student": "📶 Wi-Fi Modell (Schüler-KI)", "howitworks_key": "Das Wichtigste:", "howitworks_key_p": "Dieser Prozess findet nur einmalig bei uns statt. Beim Kunden wird **niemals** eine Kamera eingesetzt.", "howitworks_result_h": "Das Ergebnis: Anonyme Ereignisse", "howitworks_result_p": "Im Betrieb analysiert die fertig trainierte KI ausschließlich die anonymen Funksignale und klassifiziert die Haltung der Person im Raum – 100% privat und diskret.", "howitworks_input": "📡 Wi-Fi Signal", "howitworks_output": "🧍 Stehend / 🪑 Sitzend / 🛌 Liegend / 🚑 Gestürzt", "howitworks_privacy": "Ihr Vorteil:", "howitworks_privacy_p": "Sie erhalten wertvolle Informationen ohne die Privatsphäre von Personen zu verletzen.",
        "app_h2": "Anwendungsbereiche", "app_subtitle": "Von Smart Care bis Industrie.", "app_c1_h": "Gesundheit & Pflege", "app_c1_p": "Sturz, Atem, Präsenz – diskret & respektvoll.", "app_c2_h": "Smart Living", "app_c2_p": "Räume reagieren intuitiv – ohne Sprache/Touch.", "app_c3_h": "Sicherheit", "app_c3_p": "Unbefugte Präsenz in sensiblen Zonen – ohne Kamera.", "app_c4_h": "Industrie 4.0", "app_c4_p": "Gefahrenzonen-Erkennung in Echtzeit.",
        "team_h2": "Team", "team_subtitle": "Leadership: RF/Edge‑AI, Operations, Finance.", "team_m1_h": "Danilo Kuss", "team_m1_p": "CEO · Produkt, Partnerschaften, Regulatorik", "team_m2_h": "Sarah Müller", "team_m2_p": "COO · Operations, Piloten, Prozesse", "team_m3_h": "Thomas Wagner", "team_m3_p": "CTO · RF/CSI, Edge‑AI, Architektur", "team_m4_h": "Julia Schmidt", "team_m4_p": "CFO · Finanzen, Controlling, Reporting",
        "pilot_h2": "Erste Pilot-Ergebnisse (Anonymisiert)", "pilot_subtitle": "Die folgenden Daten stammen aus einem 90-tägigen Einsatz in einer führenden deutschen Pflegeeinrichtung.", "pilot_kpi1_label": "Sturzerkennung", "pilot_kpi1_desc": "Genauigkeit (True Positives)", "pilot_kpi2_label": "Präsenzerkennung", "pilot_kpi2_desc": "Latenz bis Event-Meldung", "pilot_kpi3_label": "Vitalparameter", "pilot_kpi3_desc": "Mittlere Abweichung (Atemzüge/Min)", "pilot_quote": "\"Die kamerafreie Lösung von HAVENIS-AI war der Schlüssel für die Akzeptanz bei Bewohnern und Personal. Eine bahnbrechende Technologie für die würdevolle Pflege.\"", "pilot_quote_author": "— Dr. Eva Brandt, Leitung, Seniorenpflege Zukunft GmbH",
        "part_h2": "Design‑Partner werden (limitiert)", "part_subtitle": "Gestalten Sie die Zukunft der diskreten Wahrnehmung mit und sichern Sie sich als einer der ersten Partner exklusive Vorteile.", "part_c1_h": "Ihr Vorteil", "part_c1_p": "Gestalten Sie das Produkt mit, profitieren Sie von bevorzugten Konditionen und positionieren Sie sich als Innovationsführer.", "part_c2_h": "Definierte Pilot-Ziele", "part_c2_p": "Wir definieren gemeinsam klare KPIs für den 90-Tage-Pilot, um den Mehrwert für Ihren Anwendungsfall messbar zu machen.", "part_c3_h": "Einfache Voraussetzungen", "part_c3_p": "Sie benötigen lediglich 3–6 Räume für den Test, einen technischen Ansprechpartner und die Bereitschaft für ein NDA/DPIA.", "part_btn": "🚀 Für Pilot bewerben",
        "inv_h2": "Für Investoren", "inv_subtitle": "Wir schließen unsere Pre‑Seed Runde (400–600k€) zur Skalierung unserer Pilotprojekte und zur Produktentwicklung ab.", "inv_c1_h": "Meilensteine", "inv_c1_p": "Abschluss von 2 weiteren Pilot-MoUs (Q3), Skalierung der Hardware-Integration (Q4), erste Lizenzverträge (Q1/26).", "inv_c2_h": "Use of Funds", "inv_c2_p": "KI/Software-Entwicklung (40%), Hardware-Prototyping & Piloten (30%), Personal (20%), Recht & Vertrieb (10%).", "inv_c4_h": "Direkter Draht", "inv_c4_btn1": "Pitch Deck anfordern", "inv_c4_btn2": "15‑Min Intro‑Call buchen",
        "contact_h2": "Kontakt", "contact_subtitle": "Wir freuen uns auf Ihre Nachricht und antworten innerhalb von 24 Stunden.", "contact_direct_info": "<strong>Direktkontakt</strong><br> Herr D. Kuss · Tel: <a href=\"tel:+493361747868\">+49 3361 747868</a> · Mobil: <a href=\"tel:+4915510926776\">+49 15510 926776</a><br> E‑Mail: <a href=\"mailto:HAVENIS-AI@web.de\">HAVENIS-AI@web.de</a> · Web: <a href=\"https://www.havenis-ai.vercel.app\" target=\"_blank\" rel=\"noopener\">www.havenis-ai.vercel.app</a>", "form_label_name": "Name", "form_label_email": "E‑Mail", "form_label_org": "Organisation (optional)", "form_label_msg": "Nachricht", "form_placeholder_msg": "Deine Frage oder Projektidee...", "form_label_consent": "Ich habe die <a href=\"#datenschutz\">Datenschutzhinweise</a> gelesen und akzeptiere sie.", "form_btn_send": "📨 Nachricht senden",
        "faq_h2": "Häufig gestellte Fragen (FAQ)", "faq_subtitle": "Antworten zu Technologie, Datenschutz und den Pilotprojekten.", "faq_q1": "Welche Router werden unterstützt?", "faq_a1": "Für eine präzise Erfassung benötigen wir Zugriff auf feingranulare Kanalinformationen (CSI). Dies wird von vielen modernen Wi-Fi 6/7 Access Points sowie Geräten mit OpenWrt oder spezifischen Intel/Atheros-Chipsätzen unterstützt. Die genaue Kompatibilität prüfen wir im technischen Vorgespräch.", "faq_q2": "Können einzelne Personen identifiziert oder verfolgt werden?", "faq_a2": "Nein, absolut nicht. Das System führt keine biometrische Identifikation durch. Es erkennt anonyme Muster und kann maximal die Anzahl der Personen im Raum schätzen. Alle erzeugten Ereignisse (wie \"Sturz\") sind nicht an eine Identität geknüpft.", "faq_q3": "Wie zuverlässig ist die Erkennung?", "faq_a3": "Unsere Ziel-KPIs für typische Innenräume sind eine Falsch-Negativ-Rate (übersehener Sturz) von unter 5% und eine Falsch-Positiv-Rate (Fehlalarm) von unter 8%. Die Genauigkeit hängt von Faktoren wie Raumgröße, Möblierung und Störquellen ab und wird im Pilotprojekt validiert.", "faq_q4": "Funktioniert die Erkennung auch bei mehreren Personen?", "faq_a4": "Ja. Unsere Modelle sind darauf trainiert, auch in Umgebungen mit mehreren Personen robuste Ergebnisse zu liefern, beispielsweise um die Anwesenheit in einem Raum zu zählen oder einen Sturz trotz Anwesenheit einer zweiten Person zu erkennen. Die Komplexität beeinflusst jedoch die Genauigkeit.",
        "note_strong": "Wichtiger Hinweis:", "note_p": "Dieses System ist kein zertifiziertes Medizinprodukt. Es dient der Unterstützung und Informationsgewinnung und darf nicht als alleinige Grundlage für medizinische oder sicherheitskritische Entscheidungen verwendet werden.",
        "footer_imprint": "Impressum", "footer_privacy": "Datenschutz", "footer_terms": "AGB", "footer_location": "Fürstenwalde, Deutschland | Entwicklung & Forschung", "footer_copy": "© 2025 HAVENIS-AI UG (<abbr title=\"in Gründung\">i.Gr.</abbr>)",
        "imprint_h2": "Impressum", "imprint_p1": "Angaben gemäß § 5 TMG:<br><strong>HAVENIS-AI UG (<abbr title=\"in Gründung\">i.Gr.</abbr>)</strong><br>Damaschkeweg 1<br>15517 Fürstenwalde<br>Deutschland<p class=\"mt-1\"><strong>Vertreten durch:</strong><br>Herrn Danilo Kuss</p>", "imprint_p2": "<strong>Kontakt:</strong><br>E‑Mail: <a href=\"mailto:HAVENIS-AI@web.de\">HAVENIS-AI@web.de</a><br>Telefon: <a href=\"tel:+493361747868\">+49 3361 747868</a><br>Mobil: <a href=\"tel:+4915510926776\">+49 15510 926776</a>", 
        "privacy_h2": "Datenschutzerklärung", "privacy_p1": "<strong>Verantwortlicher im Sinne der DSGVO:</strong> HAVENIS-AI UG (<abbr title=\"in Gründung\">i.Gr.</abbr>), Damaschkeweg 1, 15517 Fürstenwalde, Deutschland.", "privacy_p2": "<strong>Verarbeitungszwecke:</strong> Bereitstellung und Optimierung der Webseite, Bearbeitung von Kontaktanfragen (Art. 6 Abs. 1 lit. b DSGVO), Versand von Informationen an Design-Partner und Investoren (Art. 6 Abs. 1 lit. a DSGVO).", "privacy_p3": "<strong>Datenkategorien:</strong> Wir verarbeiten Nutzungsdaten (IP-Adresse, Browser-Version), Kontaktdaten (Name, E-Mail, Organisation) und Kommunikationsinhalte. Es findet keine Erfassung von biometrischen, Audio- oder Videodaten über diese Webseite statt.", "privacy_p4": "<strong>Speicherdauer:</strong> Kontaktdaten werden nach Abschluss der Konversation gelöscht, sofern keine gesetzlichen Aufbewahrungsfristen entgegenstehen. Daten von Interessenten werden bis zum Widerruf der Einwilligung gespeichert.", 
        "agb_h2": "Allgemeine Geschäftsbedingungen (AGB) - Pilotphase", "agb_p1": "Die folgenden Punkte stellen einen Auszug der Kernregelungen für unsere Design-Partner-Piloten dar. Detaillierte Bedingungen werden im individuellen Pilotvertrag festgelegt.", "agb_h3_1": "1. Geltungsbereich und Vertragsgegenstand", "agb_p2": "Diese Bedingungen regeln die befristete Bereitstellung unserer Hard- und Software (das \"System\") zu Test- und Evaluierungszwecken (\"Pilot\"). Das System bleibt Eigentum der HAVENIS-AI UG (<abbr title=\"in Gründung\">i.Gr.</abbr>). Dem Partner wird ein nicht-exklusives, nicht-übertragbares Nutzungsrecht für die Dauer des Piloten eingeräumt.", "agb_h3_2": "2. Leistungsumfang und Haftung", "agb_p3": "HAVENIS-AI stellt das System bereit und leistet Support bei der Installation und Konfiguration. Da es sich um ein Vorab-System handelt, wird es \"as is\" ohne Garantien für eine ununterbrochene Funktion bereitgestellt. Die Haftung für Schäden, die nicht auf Vorsatz oder grober Fahrlässigkeit beruhen, ist ausgeschlossen.", "agb_h3_3": "3. Datenschutz und Vertraulichkeit", "agb_p4": "Alle durch das System erfassten Daten werden lokal (\"on-device\") verarbeitet. Eine Übermittlung an HAVENIS-AI erfolgt nur nach expliziter Zustimmung zu Forschungszwecken und in vollständig anonymisierter Form. Beide Parteien verpflichten sich zur strengen Vertraulichkeit bezüglich der Technologie und der im Rahmen des Piloten gewonnenen Erkenntnisse (NDA)."
    },
    en: {
        "skip_to_content": "Skip to content", "nav_partners": "Design Partners", "nav_why": "Why Now?", "nav_training": "AI Training", "nav_team": "Team", "nav_pilot": "Pilot Results", "nav_inv": "Investors", "nav_call": "Intro Call", "nav_faq": "FAQ", "nav_contact": "Contact",
        "hero_h1": "AI that Senses—Without Contact", "hero_p": "Contactless detection of presence, respiration, and movement patterns—for safety, care, and comfort.", "hero_access_btn": "🚀 Early Access", "hero_tech_btn": "📶 Technology", "badge_privacy": "🔒 Privacy‑by‑Design", "badge_device": "🧠 On‑Device", "badge_wifi": "📡 Existing Wi‑Fi",
        "why_now_h2": "Why Now?", "why_now_subtitle": "Technical Maturity + Privacy Shift + Cost/Benefit.", "why_now_c1_h": "Wi‑Fi 6/7 + CSI", "why_now_c1_p": "More stable metrics, higher resolution, and reliability.", "why_now_c2_h": "Privacy Shift", "why_now_c2_p": "Growing rejection of cameras in private spaces.", "why_now_c3_h": "Edge‑AI", "why_now_c3_p": "Powerful NPUs enable local real-time analysis.", "why_now_c4_h": "Cost", "why_now_c4_p": "Uses existing APs—no dedicated sensor purchase.",
        "tech_h2": "How Wi‑Fi Sensing Works", "tech_subtitle": "Movement alters the reflection of radio signals. Our AI models interpret these tiny patterns in real time.", "tech_c1_h": "1. Signal Acquisition", "tech_c1_p": "Wi-Fi access points constantly send and receive signals. Every movement—even breathing—alters these signals in a characteristic way (CSI data).", "tech_c2_h": "2. AI Decoding", "tech_c2_p": "A local deep learning model analyzes the CSI data streams and extracts anonymous movement profiles, respiration rates, and body postures—without the cloud.", "tech_c3_h": "3. Useful Events", "tech_c3_p": "The detected patterns are translated into concrete events: Fall detected, person present, restless sleep. These events then trigger alarms or actions.",
        "howitworks_h2": "From Radio Signal to Body Posture", "howitworks_subtitle": "Our technology is based on the principle of \"Knowledge Distillation\", inspired by research from Carnegie Mellon University (\"DensePose from WiFi\").", "howitworks_train_h": "Knowledge Transfer: How the AI Learns", "howitworks_train_p": "In the lab, we teach our AI to associate Wi-Fi patterns with body postures. A camera-based AI serves as a \"teacher,\" passing its knowledge to the Wi-Fi AI (\"student\").", "howitworks_teacher": "👁️ Camera (Teacher AI)", "howitworks_arrow": "→", "howitworks_student": "📶 Wi-Fi Model (Student AI)", "howitworks_key": "The Key Takeaway:", "howitworks_key_p": "This process happens only once in our lab. A camera is **never** used at the customer's premises.", "howitworks_result_h": "The Result: Anonymous Events", "howitworks_result_p": "In operation, the fully trained AI analyzes only the anonymous radio signals and classifies the person's posture in the room—100% private and discreet.", "howitworks_input": "📡 Wi-Fi Signal", "howitworks_output": "🧍 Standing / 🪑 Sitting / 🛌 Lying / 🚑 Fallen", "howitworks_privacy": "Your Advantage:", "howitworks_privacy_p": "You receive valuable information without violating anyone's privacy.",
        "app_h2": "Areas of Application", "app_subtitle": "From Smart Care to Industry.", "app_c1_h": "Health & Care", "app_c1_p": "Fall, respiration, presence—discreet & respectful.", "app_c2_h": "Smart Living", "app_c2_p": "Spaces react intuitively—without voice/touch.", "app_c3_h": "Security", "app_c3_p": "Unauthorized presence in sensitive zones—without a camera.", "app_c4_h": "Industry 4.0", "app_c4_p": "Hazard zone detection in real-time.",
        "team_h2": "Team", "team_subtitle": "Leadership: RF/Edge‑AI, Operations, Finance.", "team_m1_h": "Danilo Kuss", "team_m1_p": "CEO · Product, Partnerships, Regulatory", "team_m2_h": "Sarah Müller", "team_m2_p": "COO · Operations, Pilots, Processes", "team_m3_h": "Thomas Wagner", "team_m3_p": "CTO · RF/CSI, Edge‑AI, Architecture", "team_m4_h": "Julia Schmidt", "team_m4_p": "CFO · Finance, Controlling, Reporting",
        "pilot_h2": "First Pilot Results (Anonymized)", "pilot_subtitle": "The following data comes from a 90-day deployment in a leading German care facility.", "pilot_kpi1_label": "Fall Detection", "pilot_kpi1_desc": "Accuracy (True Positives)", "pilot_kpi2_label": "Presence Detection", "pilot_kpi2_desc": "Latency to Event Notification", "pilot_kpi3_label": "Vitals", "pilot_kpi3_desc": "Mean Deviation (Breaths/Min)", "pilot_quote": "\"The camera-free solution from HAVENIS-AI was key to its acceptance by residents and staff. A groundbreaking technology for dignified care.\"", "pilot_quote_author": "— Dr. Eva Brandt, Director, Future Senior Care Inc.",
        "part_h2": "Become a Design Partner (Limited)", "part_subtitle": "Shape the future of discreet sensing with us and secure exclusive benefits as one of our first partners.", "part_c1_h": "Your Advantage", "part_c1_p": "Co-design the product, benefit from preferential terms, and position yourself as an innovation leader.", "part_c2_h": "Defined Pilot Goals", "part_c2_p": "We jointly define clear KPIs for the 90-day pilot to make the added value for your use case measurable.", "part_c3_h": "Simple Prerequisites", "part_c3_p": "All you need are 3–6 rooms for testing, a technical contact person, and willingness to sign an NDA/DPIA.", "part_btn": "🚀 Apply for Pilot",
        "inv_h2": "For Investors", "inv_subtitle": "We are closing our Pre-Seed round (€400–600k) to scale our pilot projects and for product development.", "inv_c1_h": "Milestones", "inv_c1_p": "Closing of 2 more pilot MoUs (Q3), scaling hardware integration (Q4), first licensing agreements (Q1/26).", "inv_c2_h": "Use of Funds", "inv_c2_p": "AI/Software Development (40%), Hardware Prototyping & Pilots (30%), Personnel (20%), Legal & Sales (10%).", "inv_c4_h": "Direct Line", "inv_c4_btn1": "Request Pitch Deck", "inv_c4_btn2": "Book 15-Min Intro Call",
        "contact_h2": "Contact", "contact_subtitle": "We look forward to your message and will respond within 24 hours.", "contact_direct_info": "<strong>Direct Contact</strong><br> Mr. D. Kuss · Phone: <a href=\"tel:+493361747868\">+49 3361 747868</a> · Mobile: <a href=\"tel:+4915510926776\">+49 15510 926776</a><br> E-mail: <a href=\"mailto:HAVENIS-AI@web.de\">HAVENIS-AI@web.de</a> · Web: <a href=\"https://www.havenis-ai.vercel.app\" target=\"_blank\" rel=\"noopener\">www.havenis-ai.vercel.app</a>", "form_label_name": "Name", "form_label_email": "Email", "form_label_org": "Organization (optional)", "form_label_msg": "Message", "form_placeholder_msg": "Your question or project idea...", "form_label_consent": "I have read and accept the <a href=\"#datenschutz\">privacy policy</a>.", "form_btn_send": "📨 Send Message",
        "faq_h2": "Frequently Asked Questions (FAQ)", "faq_subtitle": "Answers on technology, data privacy, and pilot projects.", "faq_q1": "Which routers are supported?", "faq_a1": "For precise sensing, we need access to fine-grained Channel State Information (CSI). This is supported by many modern Wi-Fi 6/7 access points, as well as devices running OpenWrt or specific Intel/Atheros chipsets. We check the exact compatibility in a technical pre-call.", "faq_q2": "Can individuals be identified or tracked?", "faq_a2": "No, absolutely not. The system does not perform biometric identification. It recognizes anonymous patterns and can, at most, estimate the number of people in the room. All generated events (like \"fall\") are not linked to an identity.", "faq_q3": "How reliable is the detection?", "faq_a3": "Our target KPIs for typical indoor spaces are a False Negative Rate (missed fall) of less than 5% and a False Positive Rate (false alarm) of less than 8%. Accuracy depends on factors like room size, furniture, and interference, and will be validated during the pilot project.", "faq_q4": "Does detection work with multiple people?", "faq_a4": "Yes. Our models are trained to deliver robust results even in multi-person environments, for example, to count presence in a room or detect a fall despite another person being present. However, complexity does affect accuracy.",
        "note_strong": "Important Note:", "note_p": "This system is not a certified medical device. It serves as a support and information-gathering tool and should not be used as the sole basis for medical or safety-critical decisions.",
        "footer_imprint": "Imprint", "footer_privacy": "Privacy", "footer_terms": "GTC", "footer_location": "Fürstenwalde, Germany | Development & Research", "footer_copy": "© 2025 HAVENIS-AI UG (<abbr title=\"in foundation\">i.Gr.</abbr>)",
        "imprint_h2": "Imprint", "imprint_p1": "Information pursuant to § 5 TMG:<br><strong>HAVENIS-AI UG (<abbr title=\"in foundation\">i.Gr.</abbr>)</strong><br>Damaschkeweg 1<br>15517 Fürstenwalde<br>Germany<p class=\"mt-1\"><strong>Represented by:</strong><br>Mr. Danilo Kuss</p>", "imprint_p2": "<strong>Contact:</strong><br>Email: <a href=\"mailto:HAVENIS-AI@web.de\">HAVENIS-AI@web.de</a><br>Phone: <a href=\"tel:+493361747868\">+49 3361 747868</a><br>Mobile: <a href=\"tel:+4915510926776\">+49 15510 926776</a>", 
        "privacy_h2": "Privacy Policy", "privacy_p1": "<strong>Controller in the sense of the GDPR:</strong> HAVENIS-AI UG (<abbr title=\"in foundation\">i.Gr.</abbr>), Damaschkeweg 1, 15517 Fürstenwalde, Germany.", "privacy_p2": "<strong>Purposes of processing:</strong> Provision and optimization of the website, processing of contact inquiries (Art. 6 para. 1 lit. b GDPR), sending information to design partners and investors (Art. 6 para. 1 lit. a GDPR).", "privacy_p3": "<strong>Data categories:</strong> We process usage data (IP address, browser version), contact data (name, email, organization), and communication content. No biometric, audio, or video data is collected via this website.", "privacy_p4": "<strong>Storage duration:</strong> Contact data is deleted after the conversation is concluded, unless statutory retention periods apply. Data from interested parties is stored until consent is revoked.",
        "agb_h2": "General Terms and Conditions (GTC) - Pilot Phase", "agb_p1": "The following points represent an excerpt of the core regulations for our design partner pilots. Detailed conditions will be specified in the individual pilot agreement.", "agb_h3_1": "1. Scope and Subject Matter", "agb_p2": "These terms govern the temporary provision of our hardware and software (the \"System\") for testing and evaluation purposes (\"Pilot\"). The System remains the property of HAVENIS-AI UG (<abbr title=\"in foundation\">i.Gr.</abbr>). The partner is granted a non-exclusive, non-transferable right of use for the duration of the pilot.", "agb_h3_2": "2. Scope of Services and Liability", "agb_p3": "HAVENIS-AI provides the System and offers support for installation and configuration. As this is a pre-release system, it is provided \"as is\" without guarantees of uninterrupted function. Liability for damages not caused by intent or gross negligence is excluded.", "agb_h3_3": "3. Data Protection and Confidentiality", "agb_p4": "All data collected by the System is processed locally (\"on-device\"). Transfer to HAVENIS-AI only occurs with explicit consent for research purposes and in a fully anonymized form. Both parties commit to strict confidentiality regarding the technology and findings from the pilot (NDA)."
    }
};
document.addEventListener('DOMContentLoaded',()=>{const e=document.getElementById("lang-switcher"),t=e.querySelectorAll(".lang-btn"),a=document.getElementById("contactForm"),n=document.querySelector(".mobile-menu-toggle"),o=document.querySelector(".main-nav");function i(i){document.documentElement.lang=i,document.documentElement.dataset.lang=i,document.querySelectorAll("[data-i18n]").forEach(e=>{const t=e.dataset.i18n;LANGUAGE_DATA[i]?.[t]&&(e.innerHTML=LANGUAGE_DATA[i][t])}),document.querySelectorAll("[data-i18n-placeholder]").forEach(e=>{const t=e.dataset.i18nPlaceholder;LANGUAGE_DATA[i]?.[t]&&(e.placeholder=LANGUAGE_DATA[i][t])});t.forEach(e=>{e.classList.toggle("active",e.dataset.langCode===i)})}t.forEach(e=>{e.addEventListener("click",e=>{i(e.target.dataset.langCode)})}),a&&a.addEventListener("submit",function(e){const t=a.querySelector('button[type="submit"]'),n="de"===document.documentElement.lang?"Sende...":"Sending...";t&&(t.disabled=!0,t.innerHTML=`\n                        <svg style="width:20px;height:20px;margin-right:8px;animation:spin 1s linear infinite" viewBox="0 0 50 50">\n                          <circle cx="25" cy="25" r="20" fill="none" stroke="currentColor" stroke-width="5" stroke-dasharray="31.4 31.4" stroke-linecap="round">\n                            <animateTransform attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="1s" repeatCount="indefinite"></animateTransform>\n                          </circle>\n                        </svg>\n                        ${n}\n                    `)}),n&& (n.addEventListener("click",()=>{const e=o.classList.toggle("is-open");n.setAttribute("aria-expanded",e),n.classList.toggle("active",e)}),o.querySelectorAll("a").forEach(e=>{e.addEventListener("click",()=>{o.classList.remove("is-open"),n.setAttribute("aria-expanded","false"),n.classList.remove("active")})}));const l=document.documentElement.dataset.lang||"de";i(l);const r=new IntersectionObserver(e=>e.forEach(e=>e.isIntersecting&&e.target.classList.add("visible")),{threshold:.12});document.querySelectorAll(".fade-in").forEach(e=>r.observe(e));const s=[...document.querySelectorAll("main section[id]")],d=[...document.querySelectorAll("nav.main-nav a[href^=\"#\"]")];const c=new IntersectionObserver(e=>e.forEach(e=>{if(e.isIntersecting){d.forEach(e=>e.removeAttribute("aria-current"));const t=d.find(t=>t.getAttribute("href")==="#"+e.target.id);t&&t.setAttribute("aria-current","true")}}),{threshold:.5});s.forEach(e=>c.observe(e));});